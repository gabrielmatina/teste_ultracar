{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ETL dos registros do Banco de Dados "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Importações\n",
    "\n",
    "#### Para este processo de importação vamos precisar importar 2 bibliotecas do Python. A biblioteca `Psycopg2` vai fazer a conexão com o banco de dados e a biblioteca `Pandas` vai nos permitir trabalhar os dados de maneira tabular, onde vai facilitar todo o processo de desde a extração, limpeza, modificação e o processo de salvar os dados em um arquivo de Excel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Acessando os dados\n",
    "\n",
    "#### Como havia instalado o Postgres em meu computador, para acessar o banco de dados foi necessário somente instalar a extensão `PostegreSQL Explorer` no VS Code. Depois foi necessário conectar meu banco de dados com a extensão informando os dados de host, database, user e passaword.\n",
    "\n",
    "#### Logo após a conexão utilizei a biblioteca `Psycopg2`para ter acesso aos dados. Utilizei a função `execute()` para fazer uma consulta em cada uma das tabelas do banco de dados, e utilizei a função `fetchall()` para armazenar todos os registros em uma variável.\n",
    "\n",
    "#### Por fim fechei a conexão com o banco de dados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "connection = psycopg2.connect(host=\"localhost\", database=\"Ultracar\", user=\"postgres\", password=\"admin\")\n",
    "\n",
    "cursor = connection.cursor()\n",
    "\n",
    "cursor.execute(\"SELECT * FROM clientes\")\n",
    "clientes = cursor.fetchall()\n",
    "\n",
    "cursor.execute(\"SELECT * FROM fornecedores\")\n",
    "fornecedores = cursor.fetchall()\n",
    "\n",
    "cursor.execute(\"SELECT * FROM funcionarios\")\n",
    "funcionarios = cursor.fetchall()\n",
    "\n",
    "cursor.execute(\"SELECT * FROM orcamentos\")\n",
    "orcamentos = cursor.fetchall()\n",
    "\n",
    "cursor.execute(\"SELECT * FROM ordens_servico\")\n",
    "ordens_servico = cursor.fetchall()\n",
    "\n",
    "cursor.execute(\"SELECT * FROM produtos\")\n",
    "produtos = cursor.fetchall()\n",
    "\n",
    "cursor.execute(\"SELECT * FROM produtos_orcamento\")\n",
    "produtos_orcamento = cursor.fetchall()\n",
    "\n",
    "cursor.execute(\"SELECT * FROM servicos\")\n",
    "servicos = cursor.fetchall()\n",
    "\n",
    "cursor.execute(\"SELECT * FROM veiculos\")\n",
    "veiculos = cursor.fetchall()\n",
    "\n",
    "\n",
    "cursor.close()\n",
    "connection.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Criando os Dataframes\n",
    "\n",
    "#### Uitilizando a biblioteca `Pandas`, criei todos os dataframes adicionando os títulos de cada coluna. Utilizei as funções `head()` e `info()` para visualizar os dados e identificar algum problema, retirei as funções ao final desta etapa para não poluir visualmente o notebook.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "clientes = pd.DataFrame(clientes, columns=[\"id_cliente\", \"nome\", \"telefone\", \"email\", \"endereco\", \"cidade\", \"estado\", \"cep\", \"data_nascimento\", \"genero\", \"status_cliente\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "fornecedores = pd.DataFrame(fornecedores, columns=[\"id_fornecedor\", \"nome_fornecedor\", \"cnpj\", \"telefone\", \"email\", \"endereco\", \"contato_responsavel\"])\n",
    "funcionarios = pd.DataFrame(funcionarios, columns=[\"id_funcionario\", \"nome_funcionario\", \"cargo\", \"salario\", \"data_contratacao\", \"data_nascimento\", \"genero\", \"telefone\", \"email\"])\n",
    "orcamentos = pd.DataFrame(orcamentos, columns=[\"id_orcamento\", \"data_orcamento\", \"valor_total\", \"status_orcamento\", \"id_cliente\", \"id_veiculo\"])\n",
    "ordens_servico = pd.DataFrame(ordens_servico, columns=[\"id_ordem_servico\", \"data_abertura\", \"data_fechamento\", \"status_os\", \"id_funcionario\", \"id_veiculo\", \"id_orcamento\", \"valor_total\"])\n",
    "produtos = pd.DataFrame(produtos, columns=[\"id_produto\", \"nome_produto\", \"descricao\", \"preco_custo\", \"preco_venda\", \"id_fornecedor\"])\n",
    "produtos_orcamento = pd.DataFrame(produtos_orcamento, columns=[\"id_produto_orcamento\", \"tipo_item\", \"id_item\", \"quantidade\", \"preco_unitario\", \"id_orcamento\"])\n",
    "servicos = pd.DataFrame(servicos, columns=[\"id_servico\", \"descricao_servico\", \"preco_servico\", \"tempo_estimado\"])\n",
    "veiculos = pd.DataFrame(veiculos, columns=[\"id_veiculo\", \"placa\", \"modelo\", \"marca\", \"ano_fabricacao\", \"cor\", \"tipo_combustivel\", \"id_cliente\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Funções para normalizar os dados\n",
    "\n",
    "#### Para facilitar o processo de normalização dos dados, resolvi criar funções para evitar reutilização de contigo.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função que deixa a primeira letra de cada palavra em maiúscula\n",
    "\n",
    "def normalizar_nome(nome):\n",
    "    clientes[\"nome\"] = clientes[\"nome\"].str.title()\n",
    "    return nome\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função que normaliza o telefone de acordo com a cidade.\n",
    "\n",
    "# 1. Substitui espaços em branco\n",
    "# 2. Remove caracteres caracteres especiais\n",
    "# 3. Remove o primeiro dígito se o telefone tiver 12 dígitos ou começar com 0\n",
    "# 4. Adiciona o DDD de acordo com a cidade\n",
    "# 5. Adiciona o hífen e os parênteses.\n",
    "\n",
    "def normalizar_telefone_com_cidade(df, telefone_col, cidade_col):\n",
    "    df[telefone_col] = df[telefone_col].str.replace(' ', '')\n",
    "    df[telefone_col] = df[telefone_col].apply(lambda x: re.sub(r'\\D', '', x))\n",
    "    df[telefone_col] = df[telefone_col].apply(lambda x: x[1:] if len(x) == 12 or x.startswith('0') else x)\n",
    "    def adicionar_ddd(telefone, cidade):\n",
    "        if len(telefone) == 9:\n",
    "            cidades = {\n",
    "                \"Belo Horizonte\": \"31\",\n",
    "                \"São Paulo\": \"11\",\n",
    "                \"Rio de Janeiro\": \"21\",\n",
    "                \"Vitória\": \"27\",\n",
    "                \"Curitiba\": \"41\",\n",
    "                \"Porto Alegre\": \"51\",\n",
    "                \"Florianópolis\": \"48\",\n",
    "                \"Brasília\": \"61\",\n",
    "                \"Goiânia\": \"62\",\n",
    "                \"Cuiabá\": \"65\",\n",
    "                \"Campo Grande\": \"67\",\n",
    "                \"Rio Branco\": \"68\",\n",
    "                \"Porto Velho\": \"69\",\n",
    "                \"Manaus\": \"92\",\n",
    "                \"Belém\": \"91\",\n",
    "                \"Macapá\": \"96\",\n",
    "                \"Palmas\": \"63\",\n",
    "                \"Boa Vista\": \"95\",\n",
    "                \"Fortaleza\": \"85\",\n",
    "                \"Natal\": \"84\",\n",
    "                \"João Pessoa\": \"83\",\n",
    "                \"Recife\": \"81\",\n",
    "                \"Maceió\": \"82\",\n",
    "                \"Salvador\": \"71\",\n",
    "                \"Aracaju\": \"79\",\n",
    "                \"Teresina\": \"86\",\n",
    "                \"São Luís\": \"98\",\n",
    "            }\n",
    "            return f\"{cidades[cidade]}{telefone}\"\n",
    "        return telefone\n",
    "    df[telefone_col] = df.apply(lambda x: adicionar_ddd(x[telefone_col], x[cidade_col]), axis=1)\n",
    "    df[telefone_col] = df[telefone_col].apply(lambda x: f\"{x[:7]}-{x[7:]}\")\n",
    "    df[telefone_col] = df[telefone_col].apply(lambda x: f\"({x[:2]}){x[2:]}\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função similar a função anetrior, porém que normatiza o telefone sem considerar a cidade.\n",
    "\n",
    "def normalizar_telefone(df, telefone_col):\n",
    "    df[telefone_col] = df[telefone_col].str.replace(' ', '', regex=False)\n",
    "    df[telefone_col] = df[telefone_col].apply(lambda x: re.sub(r'\\D', '', x))\n",
    "    df[telefone_col] = df[telefone_col].apply(lambda x: x[1:] if len(x) == 12 or x.startswith('0') else x)\n",
    "    def formatar_telefone(x):\n",
    "        if len(x) == 8: \n",
    "            return f\"{x[:4]}-{x[4:]}\"\n",
    "        elif len(x) == 9: \n",
    "            return f\"{x[:5]}-{x[5:]}\"\n",
    "        elif len(x) == 10:\n",
    "            return f\"({x[:2]}){x[2:6]}-{x[6:]}\"\n",
    "        elif len(x) == 11:\n",
    "            return f\"({x[:2]}){x[2:7]}-{x[7:]}\"\n",
    "        else:\n",
    "            return x \n",
    "    df[telefone_col] = df[telefone_col].apply(formatar_telefone)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função que altere a data do padrão americano AAAA-MM-DD para o padrão brasileiro DD/MM/AAAA\n",
    "\n",
    "def normalizar_data(data):\n",
    "    data = pd.to_datetime(data)\n",
    "    return data.strftime(\"%d/%m/%Y\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função que normaliza o CNPJ de acordo com o padrão brasileiro XX.XXX.XXX/XXXX-XX\n",
    "\n",
    "def normalizar_cnpj(cnpj):\n",
    "    cnpj = cnpj.str.replace(r'\\D', '', regex=True)\n",
    "    cnpj = cnpj.apply(lambda x: f\"{x[:2]}.{x[2:5]}.{x[5:8]}/{x[8:12]}-{x[12:]}\")\n",
    "    return cnpj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função de narmaliza a placa do veículo de acordo com o padrão brasileiro XXX-XXXX\n",
    "\n",
    "def normalizar_placa(placa):\n",
    "    placa = placa.str.replace(r'\\W', '', regex=True)\n",
    "    placa = placa.apply(lambda x: f\"{x[:3]}-{x[3:]}\")\n",
    "    return placa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Aplicar as funções para transformar os dados em cada Dataframe\n",
    "\n",
    "#### Utilizei as funções em cada Dataframe e de forma recorrente utilizei a função `head()` para verificar se os dados eram transformados da forma correta, novamente retirei a função, para melhorar a visibilidade do código."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "clientes = normalizar_telefone_com_cidade(clientes, \"telefone\", \"cidade\")\n",
    "clientes = normalizar_nome(clientes)\n",
    "clientes[\"data_nascimento\"] = clientes[\"data_nascimento\"].apply(normalizar_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "fornecedores[\"cnpj\"] = normalizar_cnpj(fornecedores[\"cnpj\"])\n",
    "fornecedores[\"contato_responsavel\"] = normalizar_nome(fornecedores[\"contato_responsavel\"])\n",
    "fornecedores = normalizar_telefone(fornecedores, \"telefone\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "funcionarios[\"nome_funcionario\"] = normalizar_nome(funcionarios[\"nome_funcionario\"])\n",
    "funcionarios[\"data_contratacao\"] = funcionarios[\"data_contratacao\"].apply(normalizar_data)\n",
    "funcionarios[\"data_nascimento\"] = funcionarios[\"data_nascimento\"].apply(normalizar_data)\n",
    "funcionarios = normalizar_telefone(funcionarios, \"telefone\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "orcamentos[\"data_orcamento\"] = orcamentos[\"data_orcamento\"].apply(normalizar_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "ordens_servico[\"data_abertura\"] = ordens_servico[\"data_abertura\"].apply(normalizar_data)\n",
    "ordens_servico[\"data_fechamento\"] = ordens_servico[\"data_fechamento\"].apply(lambda x: x if pd.isnull(x) else normalizar_data(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "veiculos[\"placa\"] = normalizar_placa(veiculos[\"placa\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Salvar dataframes em arquivo Excel\n",
    "\n",
    "#### Utilizei a função `ExcelWriter()` para salvar todos os Dataframes em um único arquivo em Excel nesta mesma pasta para iniciar o processo de DataViz com o Power BI. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arquivo salvo com sucesso!\n"
     ]
    }
   ],
   "source": [
    "with pd.ExcelWriter(\"ultracar.xlsx\") as writer:\n",
    "    clientes.to_excel(writer, sheet_name=\"clientes\", index=False)\n",
    "    fornecedores.to_excel(writer, sheet_name=\"fornecedores\", index=False)\n",
    "    funcionarios.to_excel(writer, sheet_name=\"funcionarios\", index=False)\n",
    "    orcamentos.to_excel(writer, sheet_name=\"orcamentos\", index=False)\n",
    "    ordens_servico.to_excel(writer, sheet_name=\"ordens_servico\", index=False)\n",
    "    produtos.to_excel(writer, sheet_name=\"produtos\", index=False)\n",
    "    produtos_orcamento.to_excel(writer, sheet_name=\"produtos_orcamento\", index=False)\n",
    "    servicos.to_excel(writer, sheet_name=\"servicos\", index=False)\n",
    "    veiculos.to_excel(writer, sheet_name=\"veiculos\", index=False)\n",
    "    print(\"Arquivo salvo com sucesso!\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
